{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "linear-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# Spark imports\n",
    "from pyspark.ml.feature import VectorAssembler, VectorSlicer, RobustScaler, CountVectorizer\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, OneVsRest\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, LongType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, Normalizer, VectorSlicer, OneHotEncoder\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "horizontal-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 1: Data Loading & Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "independent-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a spark session.\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "def load_df_from_csv(filename):\n",
    "    spark = init_spark()\n",
    "    df = spark.read.csv(filename, header=True, multiLine=True, quote=\"\\\"\", escape=\"\\\"\")\n",
    "    return df\n",
    "\n",
    "# UDFs used for data preprocesssing\n",
    "\n",
    "def json_list_num(all_cast):\n",
    "    cleaned = all_cast.replace(\"/\", \"\")\n",
    "    converted_list = list(eval(cleaned))\n",
    "    return len(converted_list)\n",
    "\n",
    "\n",
    "def gender_of_first_cast(all_cast):\n",
    "    cleaned = all_cast.replace(\"/\", \"\")\n",
    "    converted_list = list(eval(cleaned))\n",
    "    if converted_list and converted_list[0] and converted_list[0][\"gender\"]:\n",
    "        return converted_list[0][\"gender\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def gender_of_second_cast(all_cast):\n",
    "    cleaned = all_cast.replace(\"/\", \"\")\n",
    "    converted_list = list(eval(cleaned))\n",
    "    if converted_list and len(converted_list)>1 and converted_list[1] and converted_list[1][\"gender\"]:\n",
    "        return converted_list[1][\"gender\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def release_year(date):\n",
    "    if date:\n",
    "        return int(date[:4])\n",
    "    return date\n",
    "\n",
    "\n",
    "def release_month(date):\n",
    "    if date:\n",
    "        return int(date[5:7])\n",
    "    return date\n",
    "\n",
    "\n",
    "def imdb_title(title):\n",
    "    return title.split(\"\\xa0\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cognitive-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IMDB database\n",
    "imdb_dataset = load_df_from_csv(\"datasets\" + (\"\\\\\" if platform.system() == \"Windows\" else \"/\") + \"imdb_movie_metadata.csv\")\n",
    "\n",
    "# remove useless columns from the dataset\n",
    "imdb_dataset = imdb_dataset.drop(\"color\", \"director_name\", \"director_facebook_likes\", \"num_critic_for_reviews\",\n",
    "                                 \"actor_3_facebook_likes\", \"actor_2_name\", \"actor_1_name\",\n",
    "                                 \"actor_3_name\", \"facenumber_in_poster\", \"plot_keywords\", \"movie_imdb_link\",\n",
    "                                 \"language\", \"country\", \"title_year\", \"actor_2_facebook_likes\",\n",
    "                                 \"gross\", \"aspect_ratio\", \"actor_1_facebook_likes\",\"movie_facebook_likes\")\n",
    "\n",
    "imdb_dataset = imdb_dataset.withColumnRenamed(\"movie_title\", \"imdb_movie_title\")\n",
    "\n",
    "udf_imdb_title = udf(imdb_title, StringType())\n",
    "imdb_dataset = imdb_dataset.withColumn(\"imdb_movie_title\", udf_imdb_title(\"imdb_movie_title\"))\n",
    "\n",
    "# TMDB credits database\n",
    "crew_dataset = load_df_from_csv(\"datasets/\" + \"tmdb_5000_credits.csv\")\n",
    "\n",
    "udf_cast_num = udf(json_list_num, IntegerType())\n",
    "udf_first_cast_gender = udf(gender_of_first_cast, IntegerType())\n",
    "udf_cast_num = udf(json_list_num, IntegerType())\n",
    "udf_first_cast_gender = udf(gender_of_first_cast, IntegerType())\n",
    "udf_second_cast_gender = udf(gender_of_second_cast, IntegerType())\n",
    "\n",
    "crew_dataset = crew_dataset.withColumn(\"cast_number\", udf_cast_num(\"cast\")) \\\n",
    "    .withColumn(\"cast_number\", udf_cast_num(\"crew\")) \\\n",
    "    .withColumn(\"first_cast_gender\", udf_first_cast_gender(\"cast\")) \\\n",
    "    .withColumn(\"second_cast_gender\", udf_second_cast_gender(\"cast\"))\n",
    "\n",
    "crew_dataset = crew_dataset.drop(\"cast\", \"crew\")\n",
    "crew_dataset = crew_dataset.withColumnRenamed(\"title\", \"tmdb_movie_title\")\n",
    "\n",
    "# TMDB Movie dataset\n",
    "tmdb_dataset = load_df_from_csv(\"datasets/\" + \"tmdb_5000_movies.csv\")\n",
    "\n",
    "tmdb_dataset = tmdb_dataset.select(\"title\", \"release_date\", \"vote_average\", \"revenue\", \"id\", \"popularity\")\n",
    "\n",
    "udf_release_year = udf(release_year, IntegerType())\n",
    "udf_release_month = udf(release_month, IntegerType())\n",
    "tmdb_dataset = tmdb_dataset.withColumn(\"release_year\", udf_release_year(\"release_date\"))\n",
    "tmdb_dataset = tmdb_dataset.withColumn(\"release_month\", udf_release_month(\"release_date\"))\n",
    "\n",
    "tmdb_dataset = tmdb_dataset.drop(\"release_date\")\n",
    "\n",
    "# merge the 3 datasets\n",
    "\n",
    "two_tmdb_joined = tmdb_dataset.join(crew_dataset, crew_dataset.movie_id == tmdb_dataset.id, \"inner\").drop(\"id\").drop(\n",
    "    \"movie_id\")\n",
    "dataset = two_tmdb_joined.join(imdb_dataset, two_tmdb_joined.title == imdb_dataset.imdb_movie_title, \"inner\").drop(\n",
    "    \"imdb_movie_title\").drop(\"tmdb_movie_title\")\n",
    "\n",
    "# remove all null values\n",
    "cols = dataset.columns\n",
    "for col in cols:\n",
    "    dataset = dataset.filter(dataset[str(col)].isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certain-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast all columns from string to integer type\n",
    "dataset = (dataset.withColumn(\"vote_average\",(dataset[\"vote_average\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"cast_total_facebook_likes\",(dataset[\"cast_total_facebook_likes\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"imdb_score\",(dataset[\"imdb_score\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"budget\",(dataset[\"budget\"].cast(LongType()))))\n",
    "dataset = (dataset.withColumn(\"num_user_for_reviews\",(dataset[\"num_user_for_reviews\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"num_voted_users\",(dataset[\"num_voted_users\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"popularity\",(dataset[\"popularity\"].cast(IntegerType()))))\n",
    "dataset = dataset.filter(dataset.budget > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "starting-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 2: Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conditional-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-value categorical variable transformations\n",
    "\n",
    "\n",
    "#  Convert \"content rating\" variable using One Hot Encoder\n",
    "\n",
    "# Step 1 String Indexer part\n",
    "indexer = StringIndexer(inputCol='content_rating', outputCol='ContentIndex')\n",
    "indexed = indexer.fit(dataset).transform(dataset)\n",
    "\n",
    "# Step 2:   OneHotEncoding part\n",
    "encoder = OneHotEncoder(inputCol='ContentIndex', outputCol='OHEContentIndex')\n",
    "dataset = encoder.fit(indexed).transform(indexed)\n",
    "\n",
    "dataset = dataset.drop(\"ContentIndex\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "allied-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-value categorical variable transformations\n",
    "\n",
    "# This function takes the dataset df and split the genres column into an array of strings\n",
    "def split_genres_string(dataset, column_to_split):\n",
    "    dataset = dataset.select(\n",
    "        [\"*\", split(column_to_split, '[|]').alias('{}_arr'.format(column_to_split))]).drop(column_to_split)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def apply_countvectorizer(dataset, column):\n",
    "    '''\n",
    "    Input: dataset (dataframe) and column name that contains an array of categories \n",
    "    Output: returns the transformed dataset (dataframe) and the list of categories\n",
    "    - https://stackoverflow.com/questions/58010126/pyspark-string-array-of-dynamic-length-in-dataframe-column-to-onehot-encoded\n",
    "    - https://spark.apache.org/docs/2.4.0/api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer\n",
    "    '''\n",
    "    cv = CountVectorizer(inputCol=column, outputCol=\"{}_to_vector\".format(column), binary=True)\n",
    "    model = cv.fit(dataset)\n",
    "    model.setInputCol(column)\n",
    "    set_of_categories = model.vocabulary\n",
    "\n",
    "    # print(set_of_categories)\n",
    "    \n",
    "    dataset = model.transform(dataset)\n",
    "    return dataset, set_of_categories\n",
    "\n",
    "\n",
    "# testing genres and production_companies \n",
    "dataset = split_genres_string(dataset, \"genres\")\n",
    "dataset, genres_set = apply_countvectorizer(dataset, \"genres_arr\")\n",
    "dataset = dataset.drop(\"genres_arr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "amazing-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3810\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: integer (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- popularity: integer (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- release_month: integer (nullable = true)\n",
      " |-- cast_number: integer (nullable = true)\n",
      " |-- first_cast_gender: integer (nullable = true)\n",
      " |-- second_cast_gender: integer (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- num_voted_users: integer (nullable = true)\n",
      " |-- cast_total_facebook_likes: integer (nullable = true)\n",
      " |-- num_user_for_reviews: integer (nullable = true)\n",
      " |-- budget: long (nullable = true)\n",
      " |-- imdb_score: integer (nullable = true)\n",
      " |-- OHEContentIndex: vector (nullable = true)\n",
      " |-- genres_arr_to_vector: vector (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataset.count()) # we end up with 3810 movies\n",
    "print(dataset.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fantastic-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting profit to be represented on the scale: A-E\n",
    "\n",
    "# Step 1:   Add a profit column. Remove revenue column.\n",
    "#           Sort by profit (descending order).\n",
    "dataset = (\n",
    "    dataset.withColumn(\n",
    "        \"profit\",\n",
    "        (dataset[\"revenue\"].cast(LongType()) - dataset[\"budget\"].cast(LongType())),\n",
    "    )\n",
    "    .drop(*[\"revenue\"])\n",
    "    .sort(\"profit\", ascending=False)\n",
    ")\n",
    "# Step 2:   Add an incremental ID in the \"id\" column to assign a grade.\n",
    "#           Convert back to dataframe.\n",
    "columns = dataset.columns\n",
    "dataset = (\n",
    "    dataset.rdd.zipWithIndex()\n",
    "    .map(lambda x: (x[1],) + tuple(x[0]))\n",
    "    .toDF([\"id\"] + columns)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "reflected-ordinary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|      profit|\n",
      "+------------+\n",
      "|  2550965087|\n",
      "|   103862963|\n",
      "|   103412065|\n",
      "|    28850000|\n",
      "|    28848069|\n",
      "|      321508|\n",
      "|      303838|\n",
      "|    -9800895|\n",
      "|-12152172799|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = dataset.count() // 5\n",
    "profits = dataset.filter((dataset.id == 0) | (dataset.id == (count - 1)) | (dataset.id == count + 1) | (dataset.id == (count * 2 + 1))| (dataset.id == (count + 1) * 2) | (dataset.id == (count * 3 + 2))| (dataset.id == (count + 1) * 3) | (dataset.id == (count * 4 + 3))| (dataset.id == (count * 4 + 3)) | (dataset.id == (count*5)-1))\n",
    "profits.select(\"profit\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range A: [103862963, +inf)\n",
    "# Range B: [28850000, 103412063)\n",
    "# Range C: [321508, 28850000)\n",
    "# Range D: [-98008, 321508)\n",
    "# Range E: (-inf, -98008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:   Assign a grade in the \"profit_grade\" column, corresponding to the value.\n",
    "#           Remove id and profit columns.\n",
    "dataset = (\n",
    "    dataset.withColumn(\n",
    "        \"profit_grade\",\n",
    "        when((dataset.id >= 0) & (dataset.id < count), \"A\")\n",
    "        .when((dataset.id >= (count + 1)) & (dataset.id < count * 2 + 1), \"B\")\n",
    "        .when((dataset.id >= (count + 1) * 2) & (dataset.id < count * 3 + 2), \"C\")\n",
    "        .when((dataset.id >= (count + 1) * 3) & (dataset.id < count * 4 + 3), \"D\")\n",
    "        .otherwise(\"E\"),\n",
    "    ).drop(*[\"id\", \"profit\"])\n",
    "    # Randomize to \"unsort\" dataset.\n",
    "    .orderBy(rand())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "established-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(\"title\",\"duration\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "imposed-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vote_average: long (nullable = true)\n",
      " |-- popularity: long (nullable = true)\n",
      " |-- release_year: long (nullable = true)\n",
      " |-- release_month: long (nullable = true)\n",
      " |-- cast_number: long (nullable = true)\n",
      " |-- first_cast_gender: long (nullable = true)\n",
      " |-- second_cast_gender: long (nullable = true)\n",
      " |-- num_voted_users: long (nullable = true)\n",
      " |-- cast_total_facebook_likes: long (nullable = true)\n",
      " |-- num_user_for_reviews: long (nullable = true)\n",
      " |-- budget: long (nullable = true)\n",
      " |-- imdb_score: long (nullable = true)\n",
      " |-- OHEContentIndex: vector (nullable = true)\n",
      " |-- genres_arr_to_vector: vector (nullable = true)\n",
      " |-- profit_grade: string (nullable = false)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get the final schema\n",
    "print(dataset.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "behavioral-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data prepration for the models\n",
    "\n",
    "# Put all features in one vector\n",
    "all_feature_cols = [item for item in dataset.columns if item != \"profit_grade\"]\n",
    "assembler = VectorAssembler(inputCols=all_feature_cols, outputCol=\"userFeatures\")\n",
    "dataset = assembler.transform(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "floppy-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RobusScaler to reduce outliers\n",
    "scaler = RobustScaler(inputCol=\"userFeatures\", outputCol=\"scaledFeatures\",\n",
    "                      withScaling=True, withCentering=False,\n",
    "                      lower=0.25, upper=0.75)\n",
    "\n",
    "scalerModel = scaler.fit(dataset)\n",
    "\n",
    "# Transform each feature to have unit quantile range.\n",
    "dataset = scalerModel.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the label column to numeric format using StringIndexer\n",
    "dataset = StringIndexer(inputCol=\"profit_grade\", outputCol=\"indexedLabel\").fit(dataset).transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cosmetic-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"scaledFeatures\", outputCol=\"normalized_features\", p=1.0)\n",
    "dataset = normalizer.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "distributed-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 3.a: Random Forest Model & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "metallic-fraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel| normalized_features|\n",
      "+----------+------------+--------------------+\n",
      "|       3.0|         3.0|(48,[2,3,4,5,6,7,...|\n",
      "|       3.0|         3.0|(48,[2,3,4,5,6,7,...|\n",
      "|       3.0|         3.0|(48,[2,3,4,5,6,7,...|\n",
      "|       3.0|         3.0|(48,[0,2,3,4,5,6,...|\n",
      "|       3.0|         3.0|(48,[0,1,2,3,4,5,...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Random Forest Model accuracy = 0.592497\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "# Split data to training and test set\n",
    "trainingData, testData = dataset.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Create a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol = \"normalized_features\", numTrees=100,maxDepth=10)\n",
    "\n",
    "# Train model using the training data\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"normalized_features\").show(5)\n",
    "\n",
    "# Find the accuracy of the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Random Forest Model accuracy = %g\" % (accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "heavy-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 3.b: Logistic Regression Model & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "amateur-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model accuracy = 0.517464\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model using One Vs Rest\n",
    "\n",
    "# Create the base Logistic Regression classifier.\n",
    "lr = LogisticRegression(maxIter=20, tol=1E-6, fitIntercept=True,featuresCol='normalized_features', labelCol='indexedLabel')\n",
    "\n",
    "# Create the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr,featuresCol='normalized_features', labelCol='indexedLabel')\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "predictions = ovrModel.transform(testData)\n",
    "\n",
    "# Find the accuracy of the model\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\",predictionCol=\"prediction\", labelCol='indexedLabel')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Logistic Regression Model accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sonic-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 4: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "willing-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('budget', 0.17173164217678363), ('popularity', 0.1407144362884061), ('num_voted_users', 0.12717478260515194), ('num_user_for_reviews', 0.07319305216602837), ('release_year', 0.07164706324748484), ('OHEContentIndex', 0.04385593355082366), ('vote_average', 0.042959964843468305), ('imdb_score', 0.04032291337754476), ('first_cast_gender', 0.03962076068923135), ('cast_total_facebook_likes', 0.03915978502137939), ('cast_number', 0.03908297160829202), ('release_month', 0.03410615425972621), ('second_cast_gender', 0.032538910994601)]\n"
     ]
    }
   ],
   "source": [
    "# Use random forest's feature importance function to find the most discriminating features\n",
    "feature_importances = model.featureImportances\n",
    "feature_imp_array = feature_importances.toArray()\n",
    "\n",
    "features_list = ['vote_average',\n",
    " 'popularity',\n",
    " 'release_year',\n",
    " 'release_month',\n",
    " 'cast_number',\n",
    " 'first_cast_gender',\n",
    " 'second_cast_gender',\n",
    " 'num_voted_users',\n",
    " 'cast_total_facebook_likes',\n",
    " 'num_user_for_reviews',\n",
    " 'budget',\n",
    " 'imdb_score',\n",
    " 'OHEContentIndex']\n",
    "\n",
    "# map feature names to scores\n",
    "feat_imp_list = []\n",
    "for feature, importance in zip(features_list, feature_imp_array):\n",
    "    feat_imp_list.append((feature, importance))\n",
    "\n",
    "feat_imp_list = sorted(feat_imp_list, key=(lambda x: x[1]), reverse=True)\n",
    "\n",
    "print(feat_imp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Extra\n",
    "# Binary classification - Label movies based on whether they made profit or not\n",
    "dataset = (\n",
    "    dataset.withColumn(\n",
    "        \"profit_grade\",\n",
    "        (dataset[\"revenue\"].cast(LongType()) > dataset[\"budget\"].cast(LongType())),\n",
    "    )\n",
    "    .drop(*[\"revenue\"])\n",
    ")\n",
    "\n",
    "dataset = (dataset.withColumn(\"profit_grade\",(dataset[\"profit_grade\"].cast(IntegerType()))))\n",
    "\n",
    "print(dataset.filter(dataset.profit_grade == 1).count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "atomic-brush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Random Forest Model ARROC = 0.805384\n"
     ]
    }
   ],
   "source": [
    "# Binary Random Forest Model\n",
    "\n",
    "# Split data to training and test set\n",
    "trainingData, testData = dataset.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Create a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"profit_grade\", featuresCol = \"normalized_features\", numTrees=20,maxDepth=10)\n",
    "\n",
    "# Train model using the training data\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Find the accuracy of the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"profit_grade\", rawPredictionCol=\"prediction\")\n",
    "arroc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Binary Random Forest Model ARROC = %g\" % (arroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "instrumental-compound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Logistic Regression Model ARROC = 0.821577\n"
     ]
    }
   ],
   "source": [
    "# Binary Logistic Regression Model\n",
    "\n",
    "# Create the base Logistic Regression classifier.\n",
    "lr = LogisticRegression(maxIter=20, tol=1E-6, fitIntercept=True,featuresCol='normalized_features', labelCol='profit_grade')\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "predictions = ovrModel.transform(testData)\n",
    "\n",
    "# Find the accuracy of the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"profit_grade\", rawPredictionCol=\"prediction\")\n",
    "arroc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Binary Logistic Regression Model ARROC = %g\" % (arroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-spectacular",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
