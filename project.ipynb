{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "linear-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "# Spark imports\n",
    "from pyspark.ml.feature import VectorAssembler, VectorSlicer, RobustScaler, UnivariateFeatureSelector\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, OneVsRest\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, LongType, StringType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, Normalizer, VectorSlicer, OneHotEncoder\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "horizontal-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 1: Data Loading & Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "independent-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a spark session.\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "def load_df_from_csv(filename):\n",
    "    spark = init_spark()\n",
    "    df = spark.read.csv(filename, header=True, multiLine=True, quote=\"\\\"\", escape=\"\\\"\")\n",
    "    return df\n",
    "\n",
    "# UDFs used for data preprocesssing\n",
    "def json_list_num(all_cast):\n",
    "    cleaned = all_cast.replace(\"/\", \"\")\n",
    "    converted_list = list(eval(cleaned))\n",
    "    return len(converted_list)\n",
    "\n",
    "\n",
    "def gender_of_first_cast(all_cast):\n",
    "    cleaned = all_cast.replace(\"/\", \"\")\n",
    "    converted_list = list(eval(cleaned))\n",
    "    if converted_list and converted_list[0] and converted_list[0][\"gender\"]:\n",
    "        return converted_list[0][\"gender\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def gender_of_second_cast(all_cast):\n",
    "    cleaned = all_cast.replace(\"/\", \"\")\n",
    "    converted_list = list(eval(cleaned))\n",
    "    if converted_list and len(converted_list)>1 and converted_list[1] and converted_list[1][\"gender\"]:\n",
    "        return converted_list[1][\"gender\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def production_companies(all_production):\n",
    "    cleaned = all_production.replace(\"/\", \"\")\n",
    "    list_of_companies = list(eval(cleaned))\n",
    "    s = \"\"\n",
    "    for company in list_of_companies:\n",
    "        if len(s) > 0:\n",
    "            s += \"|\"\n",
    "        s += company[\"name\"]\n",
    "    return s\n",
    "\n",
    "\n",
    "def release_year(date):\n",
    "    if date:\n",
    "        return int(date[:4])\n",
    "    return date\n",
    "\n",
    "\n",
    "def release_month(date):\n",
    "    if date:\n",
    "        return int(date[5:7])\n",
    "    return date\n",
    "\n",
    "\n",
    "def imdb_title(title):\n",
    "    return title.split(\"\\xa0\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cognitive-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IMDB database\n",
    "imdb_dataset = load_df_from_csv(\"datasets\" + (\"\\\\\" if platform.system() == \"Windows\" else \"/\") + \"imdb_movie_metadata.csv\")\n",
    "\n",
    "# remove useless columns from the dataset\n",
    "imdb_dataset = imdb_dataset.drop(\"color\", \"director_name\", \"director_facebook_likes\", \"num_critic_for_reviews\",\n",
    "                                 \"actor_3_facebook_likes\", \"actor_2_name\", \"actor_1_name\", \"num_voted_users\",\n",
    "                                 \"actor_3_name\", \"facenumber_in_poster\", \"plot_keywords\", \"movie_imdb_link\",\n",
    "                                 \"num_user_for_reviews\", \"language\", \"country\", \"title_year\", \"actor_2_facebook_likes\",\n",
    "                                 \"aspect_ratio\", \"actor_1_facebook_likes\", \"gross\")\n",
    "\n",
    "imdb_dataset = imdb_dataset.withColumnRenamed(\"movie_title\", \"imdb_movie_title\")\n",
    "\n",
    "udf_imdb_title = udf(imdb_title, StringType())\n",
    "imdb_dataset = imdb_dataset.withColumn(\"imdb_movie_title\", udf_imdb_title(\"imdb_movie_title\"))\n",
    "\n",
    "# TMDB credits database\n",
    "crew_dataset = load_df_from_csv(\"datasets/\" + \"tmdb_5000_credits.csv\")\n",
    "\n",
    "udf_cast_num = udf(json_list_num, IntegerType())\n",
    "udf_first_cast_gender = udf(gender_of_first_cast, IntegerType())\n",
    "udf_cast_num = udf(json_list_num, IntegerType())\n",
    "udf_first_cast_gender = udf(gender_of_first_cast, IntegerType())\n",
    "udf_second_cast_gender = udf(gender_of_second_cast, IntegerType())\n",
    "\n",
    "crew_dataset = crew_dataset.withColumn(\"cast_number\", udf_cast_num(\"cast\")) \\\n",
    "    .withColumn(\"cast_number\", udf_cast_num(\"crew\")) \\\n",
    "    .withColumn(\"first_cast_gender\", udf_first_cast_gender(\"cast\")) \\\n",
    "    .withColumn(\"second_cast_gender\", udf_second_cast_gender(\"cast\"))\n",
    "\n",
    "crew_dataset = crew_dataset.drop(\"cast\", \"crew\")\n",
    "crew_dataset = crew_dataset.withColumnRenamed(\"title\", \"tmdb_movie_title\")\n",
    "\n",
    "# TMDB Movie dataset\n",
    "tmdb_dataset = load_df_from_csv(\"datasets/\" + \"tmdb_5000_movies.csv\")\n",
    "\n",
    "tmdb_dataset = tmdb_dataset.select(\"production_companies\", \"title\", \"release_date\", \"vote_average\", \"revenue\", \"id\")\n",
    "\n",
    "udf_production_companies = udf(production_companies, StringType())\n",
    "tmdb_dataset = tmdb_dataset.withColumn(\"production_companies\", udf_production_companies(\"production_companies\"))\n",
    "\n",
    "udf_release_year = udf(release_year, IntegerType())\n",
    "udf_release_month = udf(release_month, IntegerType())\n",
    "tmdb_dataset = tmdb_dataset.withColumn(\"release_year\", udf_release_year(\"release_date\"))\n",
    "tmdb_dataset = tmdb_dataset.withColumn(\"release_month\", udf_release_month(\"release_date\"))\n",
    "\n",
    "tmdb_dataset = tmdb_dataset.drop(\"release_date\")\n",
    "\n",
    "# merge the 3 datasets\n",
    "\n",
    "two_tmdb_joined = tmdb_dataset.join(crew_dataset, crew_dataset.movie_id == tmdb_dataset.id, \"inner\").drop(\"id\").drop(\n",
    "    \"movie_id\")\n",
    "dataset = two_tmdb_joined.join(imdb_dataset, two_tmdb_joined.title == imdb_dataset.imdb_movie_title, \"inner\").drop(\n",
    "    \"imdb_movie_title\").drop(\"tmdb_movie_title\")\n",
    "\n",
    "# remove all null values\n",
    "cols = dataset.columns\n",
    "for col in cols:\n",
    "    dataset = dataset.filter(dataset[str(col)].isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certain-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast all columns from string to integer type\n",
    "dataset = (dataset.withColumn(\"vote_average\",(dataset[\"vote_average\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"duration\",(dataset[\"duration\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"cast_total_facebook_likes\",(dataset[\"cast_total_facebook_likes\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"imdb_score\",(dataset[\"imdb_score\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"movie_facebook_likes\",(dataset[\"movie_facebook_likes\"].cast(IntegerType()))))\n",
    "dataset = (dataset.withColumn(\"budget\",(dataset[\"budget\"].cast(LongType()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "starting-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 2: Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conditional-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variable transformations\n",
    "\n",
    "\n",
    "#  Convert \"content rating\" variable using One Hot Encoder\n",
    "\n",
    "# Step 1 String Indexer part\n",
    "indexer = StringIndexer(inputCol='content_rating', outputCol='ContentIndex')\n",
    "indexed = indexer.fit(dataset).transform(dataset)\n",
    "\n",
    "# Step 2:   OneHotEncoding part\n",
    "encoder = OneHotEncoder(inputCol='ContentIndex', outputCol='OHEContentIndex')\n",
    "dataset = encoder.fit(indexed).transform(indexed)\n",
    "\n",
    "dataset = dataset.drop(\"ContentIndex\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "allied-sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Genres array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "['Action', 'Adventure', 'Fantasy', 'Sci-Fi', 'Thriller', 'Romance', 'Animation', 'Comedy', 'Family', 'Musical', 'Mystery', 'Western', 'Drama', 'History', 'Sport', 'Crime', 'Horror', 'War', 'Biography', 'Music', 'Documentary', 'Film-Noir']\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- vote_average: long (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- release_year: long (nullable = true)\n",
      " |-- release_month: long (nullable = true)\n",
      " |-- cast_number: long (nullable = true)\n",
      " |-- first_cast_gender: long (nullable = true)\n",
      " |-- second_cast_gender: long (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- cast_total_facebook_likes: long (nullable = true)\n",
      " |-- content_rating: string (nullable = true)\n",
      " |-- budget: string (nullable = true)\n",
      " |-- imdb_score: long (nullable = true)\n",
      " |-- movie_facebook_likes: long (nullable = true)\n",
      " |-- Action: string (nullable = false)\n",
      " |-- Adventure: string (nullable = false)\n",
      " |-- Fantasy: string (nullable = false)\n",
      " |-- Sci-Fi: string (nullable = false)\n",
      " |-- Thriller: string (nullable = false)\n",
      " |-- Romance: string (nullable = false)\n",
      " |-- Animation: string (nullable = false)\n",
      " |-- Comedy: string (nullable = false)\n",
      " |-- Family: string (nullable = false)\n",
      " |-- Musical: string (nullable = false)\n",
      " |-- Mystery: string (nullable = false)\n",
      " |-- Western: string (nullable = false)\n",
      " |-- Drama: string (nullable = false)\n",
      " |-- History: string (nullable = false)\n",
      " |-- Sport: string (nullable = false)\n",
      " |-- Crime: string (nullable = false)\n",
      " |-- Horror: string (nullable = false)\n",
      " |-- War: string (nullable = false)\n",
      " |-- Biography: string (nullable = false)\n",
      " |-- Music: string (nullable = false)\n",
      " |-- Documentary: string (nullable = false)\n",
      " |-- Film-Noir: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PROCESSING THE GENRES INTO 2 FORMATS:\n",
    "# 1) StringIndexer + OneHotEncoding => output in file \"genres_output/output-noah-index-encoded.csv\"\n",
    "# 2) StringIndexer + OneHotEncoding + VectorAssembler => output in file \"genres_output/output-noah-vector.csv\"\n",
    "initial_column_names = ['title', 'genres', 'production_companies', 'vote_average', 'revenue', 'release_year', 'release_month',\n",
    "                        'cast_number', 'first_cast_gender', 'second_cast_gender', 'duration', 'cast_total_facebook_likes', 'content_rating', 'budget',\n",
    "                        'imdb_score', 'movie_facebook_likes']\n",
    "def modify_dataset(dataset):\n",
    "    dataset = dataset.select('title', 'genres', 'production_companies', 'vote_average', 'revenue', 'release_year', 'release_month',\n",
    "                            'cast_number', 'first_cast_gender', 'second_cast_gender', 'duration', 'cast_total_facebook_likes', 'content_rating', 'budget',\n",
    "                            'imdb_score', 'movie_facebook_likes')\n",
    "\n",
    "    # dataset.show()\n",
    "    # dataset.toPandas().to_csv('output-dataset.csv')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dataset_movie_genres(dataset):\n",
    "    ''' Input: dataset (df)\n",
    "    Output: \"list\" of all unique genres from the dataset (df)\n",
    "    '''\n",
    "    getAllGenres = dataset.select('title', 'genres')\n",
    "    getAllGenres_rdd = getAllGenres.rdd\n",
    "    getAllGenres_rdd = getAllGenres_rdd.map(lambda x: (x[0], x[1].split(\"|\")))\n",
    "\n",
    "    fixedListOfGenres = getAllGenres_rdd.flatMap(lambda x: (x[1])).distinct() # This list all the distinct genres from our dataset!\n",
    "    \n",
    "    getAllGenres_df = getAllGenres_rdd.toDF([\"Title\", \"Genres array\"])\n",
    "    getAllGenres_df.printSchema()\n",
    "\n",
    "    return fixedListOfGenres\n",
    "\n",
    "\n",
    "# Add new columns, one for each genre, for each movie\n",
    "def split_column_of_genres_string_in_array(dataset):\n",
    "    ''' input: dataset as Dataframe\n",
    "    output: genres_arr as one column (Dataframe)\n",
    "    '''\n",
    "    dataset_with_newcolumn = dataset.select(\n",
    "        split(dataset.genres, '[|]').alias('genres_arr'))\n",
    "    dataset_with_newcolumn = dataset.select(\n",
    "        split(dataset.genres, '[|]').alias('genres_arr'))\n",
    "    dataset_with_newcolumn.printSchema()\n",
    "    return dataset_with_newcolumn\n",
    "\n",
    "\n",
    "def split_col_genres_in_array_rdd(dataset):\n",
    "    ''' Transform the genres column (string) into an array. Output as a rdd\n",
    "    '''\n",
    "    # index of genre in the dataset is 1\n",
    "    dataset_as_rdd = dataset.rdd.map(lambda x: tuple(\n",
    "        x[i] if i != 1 else x[1].split(\"|\") for i in range(16)))\n",
    "    return dataset_as_rdd\n",
    "\n",
    "\n",
    "def processing_dataset_genres(dataset, initial_column_names):\n",
    "    '''Takes dataset (where the genres column changed from type string -> string[] ) + list of genres (generated from dataset)\n",
    "    and output the dataset (as dataframe) after applying StringIndexer\n",
    "    '''\n",
    "    test_all_genres = get_dataset_movie_genres(dataset) # Generate all the new columns to add to dataframe\n",
    "    test_all_genres = test_all_genres.collect()\n",
    "    print(test_all_genres)\n",
    "\n",
    "    # dataset (as rdd) but the genres column String -> String[]\n",
    "    test_rdd = split_col_genres_in_array_rdd(dataset)\n",
    "\n",
    "\n",
    "    test_df = test_rdd.toDF(initial_column_names)  # turn dataset back to dataframe\n",
    "\n",
    "    # adding the new columns\n",
    "    test_df_2 = test_df\n",
    "    for new_genre in test_all_genres:\n",
    "        test_df_2 = test_df_2.withColumn(new_genre,\n",
    "                        when(array_contains(test_df.genres, new_genre), lit(new_genre))\n",
    "                        .otherwise(lit('n/a'))\n",
    "                        )\n",
    "    test_df_2.drop('genres')\n",
    "    test_df_2.printSchema()\n",
    "    # test_df_2.toPandas().to_csv('./genres_output/output-noah-result.csv')\n",
    "\n",
    "\n",
    "    # StringIndexer\n",
    "    indexed = test_df_2 \n",
    "    for new_genre in test_all_genres:\n",
    "        indexer = StringIndexer(inputCol=new_genre, outputCol='{g}_index'.format(g=new_genre))\n",
    "        indexed = indexer.fit(indexed).transform(indexed)\n",
    "        indexed = indexed.drop(new_genre)\n",
    "\n",
    "    # indexed.show()\n",
    "\n",
    "    return indexed, test_all_genres\n",
    "    \n",
    "# One Hot encoder\n",
    "def one_hot_encoder_genres(test_all_genres, indexed):\n",
    "    ''' Takes output of processing_dataset_genres() and apply one hot encoding\n",
    "    See result in file \"./genres_output/output-noah-index-encoded.csv\"\n",
    "    '''\n",
    "    inputs = [genre + '_index' for genre in test_all_genres]\n",
    "    outputs = [genre + '_ohe' for genre in test_all_genres]\n",
    "    encoder = OneHotEncoder(inputCols=inputs, outputCols=outputs)\n",
    "    model = encoder.fit(indexed)\n",
    "    encoded = model.transform(indexed)\n",
    "    return encoded, outputs\n",
    "\n",
    "dataset = modify_dataset(dataset)\n",
    "indexed, test_all_genres = processing_dataset_genres(dataset, initial_column_names)\n",
    "dataset, encoded_column_names = one_hot_encoder_genres(test_all_genres,indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "amazing-classification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811\n",
      "root\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- vote_average: integer (nullable = true)\n",
      " |-- revenue: string (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- release_month: integer (nullable = true)\n",
      " |-- cast_number: integer (nullable = true)\n",
      " |-- first_cast_gender: integer (nullable = true)\n",
      " |-- second_cast_gender: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- cast_total_facebook_likes: integer (nullable = true)\n",
      " |-- budget: long (nullable = true)\n",
      " |-- imdb_score: integer (nullable = true)\n",
      " |-- movie_facebook_likes: integer (nullable = true)\n",
      " |-- OHEContentIndex: vector (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataset.count()) # we end up with 3811 movies\n",
    "print(dataset.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fantastic-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting profit to be represented on the scale: A-E\n",
    "\n",
    "# Step 1:   Add a profit column. Remove revenue column.\n",
    "#           Sort by profit (descending order).\n",
    "dataset = (\n",
    "    dataset.withColumn(\n",
    "        \"profit\",\n",
    "        (dataset[\"revenue\"].cast(LongType()) - dataset[\"budget\"].cast(LongType())),\n",
    "    )\n",
    "    .drop(*[\"revenue\"])\n",
    "    .sort(\"profit\", ascending=False)\n",
    ")\n",
    "# Step 2:   Add an incremental ID in the \"id\" column to assign a grade.\n",
    "#           Convert back to dataframe.\n",
    "columns = dataset.columns\n",
    "dataset = (\n",
    "    dataset.rdd.zipWithIndex()\n",
    "    .map(lambda x: (x[1],) + tuple(x[0]))\n",
    "    .toDF([\"id\"] + columns)\n",
    ")\n",
    "# Step 3:   Assign a grade in the \"profit_grade\" column, corresponding to the value.\n",
    "#           Remove id and profit columns.\n",
    "count = dataset.count() // 5\n",
    "dataset = (\n",
    "    dataset.withColumn(\n",
    "        \"profit_grade\",\n",
    "        when((dataset.id >= 0) & (dataset.id < count), \"A\")\n",
    "        .when((dataset.id >= (count + 1)) & (dataset.id < count * 2 + 1), \"B\")\n",
    "        .when((dataset.id >= (count + 1) * 2) & (dataset.id < count * 3 + 2), \"C\")\n",
    "        .when((dataset.id >= (count + 1) * 3) & (dataset.id < count * 4 + 3), \"D\")\n",
    "        .otherwise(\"E\"),\n",
    "    ).drop(*[\"id\", \"profit\"])\n",
    "    # Randomize to \"unsort\" dataset.\n",
    "    .orderBy(rand())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "established-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(\"production_companies\",\"title\",\"genres\",\"duration\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "behavioral-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data prepration for the models\n",
    "\n",
    "# Put all features in one vector\n",
    "all_feature_cols = [item for item in dataset.columns if item != \"profit_grade\"]\n",
    "assembler = VectorAssembler(inputCols=all_feature_cols, outputCol=\"userFeatures\")\n",
    "dataset = assembler.transform(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "floppy-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RobusScaler to reduce outliers\n",
    "scaler = RobustScaler(inputCol=\"userFeatures\", outputCol=\"scaledFeatures\",\n",
    "                      withScaling=True, withCentering=False,\n",
    "                      lower=0.25, upper=0.75)\n",
    "\n",
    "scalerModel = scaler.fit(dataset)\n",
    "\n",
    "# Transform each feature to have unit quantile range.\n",
    "dataset = scalerModel.transform(dataset)\n",
    "\n",
    "# Convert the label column to numeric format using StringIndexer\n",
    "dataset = StringIndexer(inputCol=\"profit_grade\", outputCol=\"indexedLabel\").fit(dataset).transform(dataset)\n",
    "#labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cosmetic-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"scaledFeatures\", outputCol=\"normalized_features\", p=1.0)\n",
    "dataset = normalizer.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 3.a: Random Forest Model & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "metallic-fraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel| normalized_features|\n",
      "+----------+------------+--------------------+\n",
      "|       4.0|         4.0|(24,[1,2,3,4,5,6,...|\n",
      "|       4.0|         4.0|(24,[1,2,3,4,5,6,...|\n",
      "|       0.0|         0.0|(24,[0,1,2,3,4,5,...|\n",
      "|       4.0|         4.0|(24,[0,1,2,3,4,5,...|\n",
      "|       4.0|         4.0|(24,[0,1,2,3,4,5,...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "0.4812760055478502\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "# Split data to training and test set\n",
    "trainingData, testData = dataset.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Create a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol = \"normalized_features\", numTrees=16)\n",
    "\n",
    "# Train model using the training data\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"normalized_features\").show(5)\n",
    "\n",
    "# Find the accuracy of the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Random Forest Model accuracy = %g\" % (accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Phase 3.b: Logistic Regression Model & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base Logistic Regression classifier.\n",
    "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True,featuresCol='normalized_features', labelCol='indexedLabel')\n",
    "\n",
    "# Create the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr,featuresCol='normalized_features', labelCol='indexedLabel')\n",
    "\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol='indexedLabel')\n",
    "cv = CrossValidator(estimator=ovr, estimatorParamMaps=grid, evaluator=evaluator,parallelism=2)\n",
    "cvModel = cv.fit(dataset)\n",
    "acc = evaluator.evaluate(cvModel.transform(dataset))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "amateur-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy = 0.406736\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model using One Vs Rest\n",
    "\n",
    "# Create the base Logistic Regression classifier.\n",
    "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True,featuresCol='normalized_features', labelCol='indexedLabel')\n",
    "\n",
    "# Create the One Vs Rest Classifier.\n",
    "ovr = OneVsRest(classifier=lr,featuresCol='normalized_features', labelCol='indexedLabel')\n",
    "\n",
    "# train the multiclass model.\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "predictions = ovrModel.transform(testData)\n",
    "\n",
    "# Find the accuracy of the model\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\",predictionCol=\"prediction\", labelCol='indexedLabel')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Logistic Regression Model accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-laptop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
